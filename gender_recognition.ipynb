{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "gender-recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0553dLzY6IAnr+DZkcPmR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahranorozzadeh/DeepLearning45/blob/main/gender_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZbRiNE8pxFc",
        "outputId": "5629bedb-c5ea-4e9a-f88d-dc6f40907085"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LojO-rWiy4rR",
        "outputId": "b1576d77-b7ff-453f-f14b-a2670a86352d"
      },
      "source": [
        "!kaggle datasets download -d ashishjangra27/gender-recognition-200k-images-celeba"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading gender-recognition-200k-images-celeba.zip to /content\n",
            "100% 1.32G/1.32G [00:08<00:00, 159MB/s]\n",
            "100% 1.32G/1.32G [00:08<00:00, 169MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gal5D9z-14Gx"
      },
      "source": [
        "!unzip -qq gender-recognition-200k-images-celeba.zip "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyPIRgCn3j_H"
      },
      "source": [
        "import os\n",
        "from tensorflow.keras import layers,Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "   "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRa6xRdo5nYD",
        "outputId": "7cb6dede-2de4-4050-9e6a-1adf76fe1190"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXm2Gsbg5-qe"
      },
      "source": [
        "#Hyper Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SJah8vj6HYN"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 40\n",
        "lr = 0.001\n",
        "width = height = 64"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzR5wPwD4Nxa"
      },
      "source": [
        "#Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYsIe7_a4STG",
        "outputId": "969bdcc7-2135-4c29-86ef-3487cbb8aaaf"
      },
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "train_data = data_generator.flow_from_directory(\"Dataset/Train\",\n",
        "                                    batch_size = batch_size,\n",
        "                                    shuffle = True,\n",
        "                                    class_mode = 'binary',\n",
        "                                    target_size = (width,height))\n",
        "\n",
        "val_data = data_generator.flow_from_directory(\"Dataset/Validation\",\n",
        "                                    batch_size = batch_size,\n",
        "                                    shuffle = True,\n",
        "                                    class_mode = 'binary',\n",
        "                                    target_size = (width,height))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 160000 images belonging to 2 classes.\n",
            "Found 22598 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh-wTKtzc8y-"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "      #1st conv\n",
        "      layers.Conv2D(96,(11,11),activation='relu', input_shape=(width,height,3)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.MaxPooling2D(2),\n",
        "\n",
        "      #2nd conv\n",
        "      tf.keras.layers.Conv2D(256,(11,11),strides=(1,1),activation='relu',padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "\n",
        "      #3rd conv\n",
        "      tf.keras.layers.Conv2D(384,(3,3),strides=(1,1),activation='relu',padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "\n",
        "      #4th conv\n",
        "      tf.keras.layers.Conv2D(384,(3,3),strides=(1,1),activation='relu',padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "\n",
        "\n",
        "      #5st conv\n",
        "      tf.keras.layers.Conv2D(256,(3,3),strides=(1,1),activation='relu',padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      tf.keras.layers.MaxPooling2D(2,strides=(2,2)),\n",
        "\n",
        "\n",
        "      layers.Flatten(),\n",
        "\n",
        "\n",
        "      #MLP , Classsification\n",
        "\n",
        "      #To FC layer 1\n",
        "      tf.keras.layers.Dense(4096,activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "      #To FC layer 2\n",
        "      tf.keras.layers.Dense(4096,activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Dense(1,activation='sigmoid'),\n",
        "\n",
        "]) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMj1Vk42oi9v",
        "outputId": "2636fcae-6dfe-447c-f061-b497529e110c"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=Adam(lr=0.001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuaMsvjupGwO",
        "outputId": "cb4e6a0f-8c9d-4ba8-a6ee-d09c5fd7a6b5"
      },
      "source": [
        "model.fit(train_data,\n",
        "          validation_data=val_data,\n",
        "          epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "625/625 [==============================] - 959s 1s/step - loss: 1.1088 - accuracy: 0.7919 - val_loss: 0.4001 - val_accuracy: 0.8012\n",
            "Epoch 2/40\n",
            "625/625 [==============================] - 889s 1s/step - loss: 0.2019 - accuracy: 0.9207 - val_loss: 0.3718 - val_accuracy: 0.8307\n",
            "Epoch 3/40\n",
            "625/625 [==============================] - 889s 1s/step - loss: 0.1637 - accuracy: 0.9365 - val_loss: 0.1490 - val_accuracy: 0.9400\n",
            "Epoch 4/40\n",
            "625/625 [==============================] - 890s 1s/step - loss: 0.1490 - accuracy: 0.9435 - val_loss: 0.1474 - val_accuracy: 0.9441\n",
            "Epoch 5/40\n",
            "625/625 [==============================] - 890s 1s/step - loss: 0.1426 - accuracy: 0.9465 - val_loss: 0.4927 - val_accuracy: 0.7595\n",
            "Epoch 6/40\n",
            "625/625 [==============================] - 890s 1s/step - loss: 0.1348 - accuracy: 0.9503 - val_loss: 0.1332 - val_accuracy: 0.9526\n",
            "Epoch 7/40\n",
            "625/625 [==============================] - 889s 1s/step - loss: 0.1278 - accuracy: 0.9531 - val_loss: 0.1319 - val_accuracy: 0.9534\n",
            "Epoch 8/40\n",
            "625/625 [==============================] - 889s 1s/step - loss: 0.1218 - accuracy: 0.9561 - val_loss: 0.3483 - val_accuracy: 0.8555\n",
            "Epoch 9/40\n",
            "625/625 [==============================] - 889s 1s/step - loss: 0.1202 - accuracy: 0.9568 - val_loss: 0.1410 - val_accuracy: 0.9457\n",
            "Epoch 10/40\n",
            "625/625 [==============================] - 888s 1s/step - loss: 0.1102 - accuracy: 0.9606 - val_loss: 0.1150 - val_accuracy: 0.9584\n",
            "Epoch 11/40\n",
            "625/625 [==============================] - 887s 1s/step - loss: 0.1033 - accuracy: 0.9630 - val_loss: 0.1032 - val_accuracy: 0.9597\n",
            "Epoch 12/40\n",
            "625/625 [==============================] - 884s 1s/step - loss: 0.0966 - accuracy: 0.9659 - val_loss: 0.0933 - val_accuracy: 0.9621\n",
            "Epoch 13/40\n",
            "625/625 [==============================] - 878s 1s/step - loss: 0.0907 - accuracy: 0.9685 - val_loss: 0.1034 - val_accuracy: 0.9617\n",
            "Epoch 14/40\n",
            "625/625 [==============================] - 877s 1s/step - loss: 0.0864 - accuracy: 0.9699 - val_loss: 0.1917 - val_accuracy: 0.9264\n",
            "Epoch 15/40\n",
            "625/625 [==============================] - 875s 1s/step - loss: 0.1282 - accuracy: 0.9573 - val_loss: 0.9371 - val_accuracy: 0.5490\n",
            "Epoch 16/40\n",
            " 35/625 [>.............................] - ETA: 13:15 - loss: 0.1625 - accuracy: 0.9426"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A90jMOhlqe3u"
      },
      "source": [
        "model.save('/content/drive/MyDrive/gender_model.h5')"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}